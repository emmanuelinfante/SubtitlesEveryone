{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MabnNxm5MAuS",
        "IIILsnqTUn6H"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelinfante/SubtitlesEveryone/blob/main/SubtitlesEveryone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eb38cc7"
      },
      "source": [
        "#**üìù¬°SubtitlesForEveryone!** Transcribe and translate for free"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bce6f74"
      },
      "source": [
        "Welcome to the official **SubtitlesForEveryone** notebook!\n",
        "\n",
        ">This notebook compiles and facilitates the use of artificial intelligence tools for audio transcription and translation. If you need to create subtitles for your movie or video, you just have to follow the instructions I'll provide below, and you'll see how easy it is.\n",
        "\n",
        "## How to Get Started? üöÄ\n",
        "\n",
        "1. **Enable the GPU**: For fast transcription, make sure to enable the GPU. Go to \"Runtime\" > \"Change runtime type\" > and select \"T4 GPU\" in the \"Hardware accelerator\" option.\n",
        "2. **Upload your audio or Paste a YouTube URL**: Use the tool below to upload your audio file or use the tool to import your YouTube video.\n",
        "3. **Run the cells**: Simply run the cells in order, and you'll see the magic happen! ‚ú®\n",
        "\n",
        "**Note**: If you're new to Google Colab, each code cell is executed by clicking the play button (‚ñ∂Ô∏è) on the left of the cell, or you can press `Shift + Enter`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Installation of necessary packages! üì¶**\n",
        "First, we need to download all the necessary libraries to make this notebook work!"
      ],
      "metadata": {
        "id": "MabnNxm5MAuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installation of lightweight but necessary packages\"\n",
        "!pip install srtranslator\n",
        "!pip3 install ip-rotator\n",
        "!pip install yt-dlp\n",
        "!pip install srt\n",
        "!pip install translators\n",
        "!pip install vtt-to-srt3"
      ],
      "metadata": {
        "id": "OlXUcub9JN3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of fundamental packages\n",
        "!pip install demucs\n",
        "!pip install git+https://github.com/m-bain/whisperx"
      ],
      "metadata": {
        "id": "6eMn2-9OLeqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Now, create your subtitle!** üìú"
      ],
      "metadata": {
        "id": "Cl0GmU4fMSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**1. Upload your audio file üìª**\n",
        "\n",
        "#@markdown Click the button below to upload your audio file. Make sure it is an MP3 format file.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "\n",
        "# Renombra el archivo de audio\n",
        "import os\n",
        "os.rename(audio_file, \"audio.mp3\")\n",
        "\n",
        "#change sample rate\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def convertir_frecuencia(archivo_entrada, archivo_salida):\n",
        "  # Cargar el archivo de audio\n",
        "  senal, frecuencia_muestreo = librosa.load(archivo_entrada)\n",
        "\n",
        "  # Convertir a mono\n",
        "  senal_mono = librosa.to_mono(senal)\n",
        "\n",
        "  # Nueva frecuencia de muestreo\n",
        "  nueva_frecuencia = 16000\n",
        "\n",
        "  # Convertir la se√±al a la nueva frecuencia\n",
        "  senal_convertida = librosa.resample(senal, orig_sr=frecuencia_muestreo, target_sr=nueva_frecuencia)\n",
        "\n",
        "  # Guardar el archivo de audio convertido\n",
        "  sf.write(archivo_salida, senal_convertida, nueva_frecuencia)\n",
        "\n",
        "# Ejemplo de uso\n",
        "archivo_entrada = \"audio.mp3\"\n",
        "archivo_salida = \"audio_16_000.mp3\"\n",
        "\n",
        "convertir_frecuencia(archivo_entrada, archivo_salida)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IygHVyguN4JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import warnings\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "Type = \"Youtube video or playlist\"\n",
        "#@markdown # Download the audio from your YouTube video üìÄ\n",
        "URL = \"\" #@param {type:\"string\"}\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "  ydl_opts = {\n",
        "    'format': 'm4a/bestaudio/best',\n",
        "    'outtmpl': 'audio',  # Rename the extracted MP3 file to \"audio.mp3\"\n",
        "    'postprocessors': [{\n",
        "      'key': 'FFmpegExtractAudio',\n",
        "      'preferredcodec': 'mp3',\n",
        "    }]\n",
        "  }\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download([URL])\n",
        "    list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "#change sample rate\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def convertir_frecuencia(archivo_entrada, archivo_salida):\n",
        "  # Cargar el archivo de audio\n",
        "  senal, frecuencia_muestreo = librosa.load(archivo_entrada)\n",
        "\n",
        "  # Convertir a mono\n",
        "  senal_mono = librosa.to_mono(senal)\n",
        "\n",
        "  # Nueva frecuencia de muestreo\n",
        "  nueva_frecuencia = 16000\n",
        "\n",
        "  # Convertir la se√±al a la nueva frecuencia\n",
        "  senal_convertida = librosa.resample(senal, orig_sr=frecuencia_muestreo, target_sr=nueva_frecuencia)\n",
        "\n",
        "  # Guardar el archivo de audio convertido\n",
        "  sf.write(archivo_salida, senal_convertida, nueva_frecuencia)\n",
        "\n",
        "# Ejemplo de uso\n",
        "archivo_entrada = \"audio.mp3\"\n",
        "archivo_salida = \"audio_16_000.mp3\"\n",
        "\n",
        "convertir_frecuencia(archivo_entrada, archivo_salida)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_s5iwIAToIzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *Extract vocals From Audio (Alpha)*\n",
        "#@markdown (Optional, but <font color=4bb340> **Highly Recommended** <font color=d5d5d5> to use):\n",
        "#@markdown - Great Improvement In Eastern Languages!\n",
        "#@markdown - Prevents WhisperX from Confusing Background Sounds with Speech.\n",
        "#@markdown - Enhances transcription with any language.\n",
        "#@markdown - Thanks to this extraction, it will be very rare and unlikely that you have errors in your transcription.\n",
        "\n",
        "#@markdown **Only issue:** It still cannot be used with one-hour long audios. It works very well with 30-minute audios.\n",
        "!python -m demucs.separate /content/audio_16_000.mp3 --mp3 --mp3-bitrate 128 -n hdemucs_mmi --out /content --mp3-preset 7 -d cuda --two-stems=vocals"
      ],
      "metadata": {
        "id": "meHB6u3Uy5t5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **2. Voice Transcription ‚úçÔ∏è**\n",
        "#@markdown Now, let's transcribe your audio file.\n",
        "import whisperx\n",
        "import gc\n",
        "\n",
        "audio_file = \"/content/audio_16_000.mp3\" #@param ['/content/hdemucs_mmi/audio_16_000/vocals.mp3', '/content/audio_16_000.mp3']\n",
        "from_language= '' #@param ['af', 'am', 'ar', 'as', 'az', 'ba', 'be', 'bg', 'bn', 'bo', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'gl', 'gu', 'ha', 'haw', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jw', 'ka', 'kk', 'km', 'kn', 'ko', 'la', 'lb', 'ln', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'ne', 'nl', 'nn', 'no', 'oc', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sa', 'sd', 'si', 'sk', 'sl', 'sn', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'yi', 'yo', 'zh']{allow-input: true}\n",
        "device = \"cuda\"\n",
        "chunk_size = 10\n",
        "batch_size = 16\n",
        "compute_type = \"float16\"\n",
        "beam_size = 10\n",
        "no_align = True\n",
        "print_progress = True\n",
        "\n",
        "model = whisperx.load_model(\"large-v3\", device, compute_type=compute_type)\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "\n",
        "# Transcription\n",
        "result = model.transcribe(\n",
        "    audio,\n",
        "    batch_size=batch_size,\n",
        "    chunk_size=chunk_size,\n",
        "    language=from_language,\n",
        "    print_progress=print_progress\n",
        ")\n",
        "print(result[\"segments\"])\n",
        "\n",
        "#srt\n",
        "from whisperx.utils import WriteSRT\n",
        "\n",
        "audio_filename = audio_file.split(\"/\")[-1]\n",
        "srt_filename = audio_filename.split(\".\")[0] + \".srt\"\n",
        "\n",
        "with open(srt_filename, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writesrt=WriteSRT(\".\")  #output file directory\n",
        "    writesrt.write_result(result=result, file=srt,options={\"max_line_width\":None,\"max_line_count\":None,\"highlight_words\":False,\"chunk_size\":10})\n",
        "\n",
        "#vtt\n",
        "from whisperx.utils import WriteSRT\n",
        "\n",
        "audio_filename = audio_file.split(\"/\")[-1]\n",
        "srt_filename = audio_filename.split(\".\")[0] + \".vtt\"\n",
        "\n",
        "with open(srt_filename, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writesrt=WriteSRT(\".\")  #output file directory\n",
        "    writesrt.write_result(result=result, file=srt,options={\"max_line_width\":None,\"max_line_count\":None,\"highlight_words\":False,\"chunk_size\":10})\n",
        "\n",
        "#@markdown - If you want WhisperX to automatically detect which language it is, you just need to leave \"from_language\" empty, that is, it should not contain any characters, for automatic detection.\n",
        "\n",
        "#@markdown For vocal input: _**/content/hdemucs_mmi/audio_16_000/vocals.mp3**_\n",
        "\n",
        "#@markdown For original audio input: _**/content/audio_16_000.mp3**_\n",
        "\n",
        "### Download vocals.vtt üìÇ\n",
        "Download_vocals_vtt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_vtt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals.vtt\")\n",
        "### Download vocals.srt üìÇ\n",
        "Download_vocals_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals.srt\")\n",
        "\n",
        "### Download audio_16_000.vtt üìÇ\n",
        "Download_audio_16_000_vtt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_vtt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000.vtt\")\n",
        "### Download audio_16_000.srt üìÇ\n",
        "Download_audio_16_000_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000.srt\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nEtnuVGSpkfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **3. Translate your Subtitle! üåç**\n",
        "#@markdown Transcribe your subtitle and translate it into another language. You can use more than 6 translators to choose from.\n",
        "import ip_rotator\n",
        "proxy = ip_rotator.Proxy(https = True)\n",
        "import translators\n",
        "import srt\n",
        "\n",
        "def get_user_input():\n",
        "  \"\"\"Prompts the user to choose the SRT file and returns the filename.\"\"\"\n",
        "  while True:\n",
        "    filename = input(\"Enter the SRT filename (audio_16_000.srt or vocals.srt): \")\n",
        "    if filename in (\"audio_16_000.srt\", \"vocals.srt\"):\n",
        "      return filename\n",
        "    else:\n",
        "      print(\"Invalid filename. Please choose 'audio_16_000.srt' or 'vocals.srt'.\")\n",
        "\n",
        "# Read the original SRT file based on user input\n",
        "filename = get_user_input()\n",
        "base_filename, _ = os.path.splitext(filename)  # Extract base filename without extension\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "  subtitles = srt.parse(f.read())\n",
        "\n",
        "# Function to translate a subtitle (consider error handling)\n",
        "def translate_subtitle(subtitle):\n",
        "  try:\n",
        "    translated_content = translators.translate_text(\n",
        "        query_text=subtitle.content,\n",
        "        from_language=\"auto\"#@param {type:\"string\"}\n",
        "        ,\n",
        "        to_language=\"en\"#@param {type:\"string\"}\n",
        "        ,\n",
        "        translator=\"google\" #@param ['alibaba', 'apertium', 'argos', 'baidu', 'bing', 'caiyun', 'cloudTranslation', 'elia', 'google', 'hujiang', 'iciba', 'iflytek', 'iflyrec', 'itranslate', 'judic', 'languageWire', 'lingvanex', 'niutrans', 'mglip', 'mirai', 'modernMt', 'myMemory', 'papago', 'qqFanyi', 'qqTranSmart', 'reverso', 'sogou', 'sysTran', 'tilde', 'translateCom', 'translateMe', 'utibet', 'volcEngine', 'yandex', 'yeekit', 'youdao']{allow-input: true}\n",
        "    )\n",
        "    print(f\" Subtitle Results {subtitle.index}:\")\n",
        "    print(f\"  Original: {subtitle.content}\")\n",
        "    print(f\"  Translation: {translated_content}\")\n",
        "    return srt.Subtitle(subtitle.index, subtitle.start, subtitle.end, translated_content)\n",
        "  except Exception as e:  # Catch potential translation errors\n",
        "    print(f\"Error translating subtitle {subtitle.index}: {e}\")\n",
        "    return subtitle  # Return the original subtitle if translation fails\n",
        "\n",
        "# Translate each subtitle\n",
        "translated_subtitles = [translate_subtitle(subtitle) for subtitle in subtitles]\n",
        "\n",
        "# Write the translated subtitles to a new file with modified name\n",
        "translated_filename = f\"{base_filename}_translated_by_translators.srt\"\n",
        "with open(translated_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write(srt.compose(translated_subtitles))\n",
        "\n",
        "### Download the translated SRT file (optional)\n",
        "Download_srt = False  # Set to True to download the file\n",
        "\n",
        "if Download_srt:\n",
        "  from google.colab import files  # Assuming you're using Google Colab\n",
        "  files.download(translated_filename)\n",
        "\n",
        "### Download result srt üìÇ\n",
        "Download_audio_16_000_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000_translated_by_translators.srt\")\n",
        "\n",
        "### Download result srt üìÇ\n",
        "Download_vocals_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals_translated_by_translators.srt\")\n",
        "\n",
        "#@markdown For vocal subtitle: _**/content/vocals.srt**_\n",
        "\n",
        "#@markdown For original audio subtitle: _**/content/audio_16_000.srt**_"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nVoPlS2N4CiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=somblue>**DeepL Unlimited Subtitles!** <font color=d5d5d5> *Best Translator.*\n",
        "#@markdown Translate your subtitles with great precision using DeepL Unlimitedly!\n",
        "Source_Language = \"auto\" # @param ['ar', 'auto', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'uk', 'zh']{allow-input: true}\n",
        "\n",
        "#@title Target Language\n",
        "Target_Language = \"en\" #@param ['ar', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'uk', 'zh']{allow-input: true}\n",
        "\n",
        "import os\n",
        "\n",
        "# SRT File\n",
        "from srtranslator import SrtFile\n",
        "\n",
        "from srtranslator.translators.pydeeplx import PyDeepLX\n",
        "translator = PyDeepLX()\n",
        "filepath = \"/content/vocals.srt\" #@param ['/content/audio_16_000.srt','/content/vocals.srt']\n",
        "\n",
        "# SRT File\n",
        "sub = SrtFile(filepath)\n",
        "# Translate\n",
        "sub.translate(translator, Source_Language, Target_Language)\n",
        "\n",
        "# Making the result subtitles prettier\n",
        "sub.wrap_lines()\n",
        "sub.save(f\"{os.path.splitext(filepath)[0]}_translated_by_DeepL.srt\")\n",
        "\n",
        "### Download result üìÇ\n",
        "Download_vocal_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocal_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals_translated_by_DeepL.srt\")\n",
        "\n",
        "### Download result üìÇ\n",
        "Download_audio_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000_translated_by_DeepL.srt\")\n",
        "\n",
        "#@markdown For vocal subtitle: _**/content/vocals.srt**_\n",
        "\n",
        "#@markdown For original audio subtitle: _**/content/audio_16_000.srt**_\n",
        "\n",
        "#@markdown **Warning:**\n",
        "#@markdown *Using this translator will ensure very good translations, but it's not fast. The duration of the translation process depends on the length of your subtitle to translate.*\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vDeu5bZGTWuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Languages available for DeepL. üó®Ô∏è**"
      ],
      "metadata": {
        "id": "IIILsnqTUn6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "'auto': Auto\n",
        "'ar': Arabic\n",
        "'bg': Bulgaria\n",
        "'cs': Czech\n",
        "'da': Danish\n",
        "'de': German\n",
        "'el': Greek\n",
        "'en': English\n",
        "'es': Spanish\n",
        "'et': Estonian\n",
        "'fi': Finnish\n",
        "'fr': French\n",
        "'hu': Hungarian\n",
        "'id': Indonesian\n",
        "'it': Italian\n",
        "'ja': Japanese\n",
        "'ko': Korean\n",
        "'lt': Lithuanian\n",
        "'lv': Latvian\n",
        "'nb': Norwegian Bokm√•l\n",
        "'nl': Dutch\n",
        "'pl': Polish\n",
        "'pt': Portuguese\n",
        "'ro': Romanian\n",
        "'ru': Russian\n",
        "'sk': Slovak\n",
        "'sl': Slovenian\n",
        "'sv': Swedish\n",
        "'tr': Turkish\n",
        "'uk': Ukrainian\n",
        "'zh': Chinese\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BEd1NVOvZmTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Credits and Special Thanks**\n",
        "This notebook combines many free libraries from Github and PyPI to achieve its purpose. Below, I will share what they are:\n",
        "\n",
        "- [**WhisperX** - Artificial Intelligence for Transcription](https://github.com/m-bain/whisperX)\n",
        "- [**Translators** - Library with API for over 10 languages](https://pypi.org/project/translators/)\n",
        "- [**Srt** - Necessary for reading .srt files](https://pypi.org/project/srt/)\n",
        "- [**Demucs** - For voice extraction](https://pypi.org/project/demucs/)\n",
        "- [**Ctranslate2** - Necessary for WhisperX](https://pypi.org/project/ctranslate2/)\n",
        "- [**Yt-dlp** - for video downloading](https://pypi.org/project/yt-dlp/)\n",
        "- [**Ip-Rotator** - Proxy for APIs](https://pypi.org/project/ip-rotator/)\n",
        "- [**Srtranslator** - Subtitle Translation with Deepl](https://pypi.org/project/srtranslator/)\n",
        "\n",
        "Important Clarification, this notebook also uses its own code for subtitle creation; Translators **was not created to translate subtitles, I had to write the code myself to make it work that way.** Still, I greatly appreciate the team behind all these projects, they are crucial to making this project possible! With nothing more to say, Enjoy this project!"
      ],
      "metadata": {
        "id": "TwtSHHeDRbb3"
      }
    }
  ]
}