{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MabnNxm5MAuS",
        "IIILsnqTUn6H"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emmanuelinfante/SubtitlesEveryone/blob/main/SubtitlesForEveryone(Spanish).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eb38cc7"
      },
      "source": [
        "#**üìù¬°SubtitlesForEveryone!** Transcribe y traduce de forma gratuita."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bce6f74"
      },
      "source": [
        "¬°Bienvenido al notebook oficial de **SubtitlesForEveryone**!\n",
        "\n",
        ">Este Notebook, recopila y facilita el uso de herramientas de inteligencia artificial para la transcripcion y traduccion de audio. Si necesitas crear subtitulos de tu pelicula o de un video, solo tienes que seguir las indicaciones que te proporcionar√© a continuaci√≥n, y comprobar√°s lo f√°cil que es.\n",
        "\n",
        "## ¬øC√≥mo empezar? üöÄ\n",
        "\n",
        "1. **Habilita la GPU**: Para obtener una transcripci√≥n r√°pida, aseg√∫rate de habilitar la GPU. Ve a \"Entorno de ejecuci√≥n\" > \"Cambiar tipo de entorno de ejecuci√≥n\" > y selecciona \"T4 GPU\" en la opci√≥n \"Acelerador de hardware\".\n",
        "2. **Sube tu audio o Pega Una URL de Youtube**: Usa la herramienta de abajo para subir tu archivo de audio o usa la herramienta para importar tu video de youtube.\n",
        "3. **Ejecuta las celdas**: Simplemente ejecuta las celdas en orden, ¬°y ver√°s la magia suceder! ‚ú®\n",
        "\n",
        "**Nota**: Si eres nuevo en Google Colab, cada celda con c√≥digo se ejecuta haciendo clic en el bot√≥n de reproducci√≥n (‚ñ∂Ô∏è) a la izquierda de la celda, o puedes presionar `Shift + Enter`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. ¬°Instalaci√≥n de paquetes necesarios! üì¶**\n",
        "Primero, necesitamos descargar todas las librerias necesarias para hacer funcionar este notebook!"
      ],
      "metadata": {
        "id": "MabnNxm5MAuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalacion de paquetes livianos pero necesarios\n",
        "!pip install srtranslator\n",
        "!pip3 install ip-rotator\n",
        "!pip install yt-dlp\n",
        "!pip install srt\n",
        "!pip install translators"
      ],
      "metadata": {
        "id": "OlXUcub9JN3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalacion de paquetes fundamentales\n",
        "!pip install demucs\n",
        "!pip install git+https://github.com/m-bain/whisperx"
      ],
      "metadata": {
        "id": "6eMn2-9OLeqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ahora si, Crea tu subtitulo!** üìú"
      ],
      "metadata": {
        "id": "Cl0GmU4fMSkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **1. Sube tu archivo de audio üìª**\n",
        "#@markdown Haz clic en el bot√≥n de abajo para subir tu archivo de audio. Aseg√∫rate de que sea un archivo en formato MP3.\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "\n",
        "# Renombra el archivo de audio\n",
        "import os\n",
        "os.rename(audio_file, \"audio.mp3\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IygHVyguN4JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import warnings\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "Type = \"Youtube video or playlist\"\n",
        "#@markdown # Descarga el audio de su video de youtube üìÄ\n",
        "URL = \"\" #@param {type:\"string\"}\n",
        "#@markdown Tardara unos segundos en cargar, porfavor, sea paciente.\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "  ydl_opts = {\n",
        "    'format': 'm4a/bestaudio/best',\n",
        "    'outtmpl': 'audio',  # Rename the extracted MP3 file to \"audio.mp3\"\n",
        "    'postprocessors': [{\n",
        "      'key': 'FFmpegExtractAudio',\n",
        "      'preferredcodec': 'mp3',\n",
        "    }]\n",
        "  }\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    error_code = ydl.download([URL])\n",
        "    list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "#change sample rate\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def convertir_frecuencia(archivo_entrada, archivo_salida):\n",
        "  # Cargar el archivo de audio\n",
        "  senal, frecuencia_muestreo = librosa.load(archivo_entrada)\n",
        "\n",
        "  # Convertir a mono\n",
        "  senal_mono = librosa.to_mono(senal)\n",
        "\n",
        "  # Nueva frecuencia de muestreo\n",
        "  nueva_frecuencia = 16000\n",
        "\n",
        "  # Convertir la se√±al a la nueva frecuencia\n",
        "  senal_convertida = librosa.resample(senal, orig_sr=frecuencia_muestreo, target_sr=nueva_frecuencia)\n",
        "\n",
        "  # Guardar el archivo de audio convertido\n",
        "  sf.write(archivo_salida, senal_convertida, nueva_frecuencia)\n",
        "\n",
        "# Ejemplo de uso\n",
        "archivo_entrada = \"audio.mp3\"\n",
        "archivo_salida = \"audio_16_000.mp3\"\n",
        "\n",
        "convertir_frecuencia(archivo_entrada, archivo_salida)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_s5iwIAToIzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # *Extraer las vocales del audio*\n",
        "#@markdown (Opcional, pero <font color=4bb340> **Altamente Recomendable** <font color=d5d5d5> usarlo):\n",
        "#@markdown - ¬°Gran Mejora En Idiomas Orientales!\n",
        "#@markdown - Evita que WhisperX Confunda Sonidos de Fondo con el Habla.\n",
        "#@markdown - Mejora la transcripcion con cualquier idioma.\n",
        "#@markdown - Gracias a esta extraccion, sera muy raro e improbable que tengas errores en tu transcripcion.\n",
        "\n",
        "#@markdown **Ahora funciona con audios mayores de 30 minutos!** No importa la duracion, puedes usar audios incluso de 10 horas!\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "from pydub import AudioSegment\n",
        "import demucs.separate\n",
        "import shutil\n",
        "\n",
        "# Definir la duraci√≥n m√°xima en segundos (30 minutos)\n",
        "max_duration = 30 * 60\n",
        "\n",
        "# Cargar el audio\n",
        "audio_path = '/content/audio_16_000.mp3'\n",
        "audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "# Obtener la duraci√≥n del audio en segundos\n",
        "duration = librosa.get_duration(filename=audio_path)\n",
        "\n",
        "# Si la duraci√≥n es mayor que la duraci√≥n m√°xima, dividir el audio\n",
        "if duration > max_duration:\n",
        "    # Calcular el n√∫mero de segmentos\n",
        "    num_segments = int(duration // max_duration) + 1\n",
        "\n",
        "    # Dividir el audio en segmentos y guardar cada segmento como un nuevo archivo de audio\n",
        "    for i in range(num_segments):\n",
        "        start_time = i * max_duration\n",
        "        end_time = (i + 1) * max_duration if (i + 1) * max_duration < duration else duration\n",
        "        segment = audio[start_time * 1000:end_time * 1000]  # pydub trabaja en milisegundos\n",
        "        segment_path = f'{os.path.splitext(audio_path)[0]}_segment{i}{os.path.splitext(audio_path)[1]}'\n",
        "        segment.export(segment_path, format='wav')\n",
        "\n",
        "        # Aplicar demucs a cada archivo de audio\n",
        "        demucs.separate.main([\"-d\", \"cuda\", \"--mp3\", \"--mp3-bitrate\", \"96\", \"--two-stems=vocals\", \"-n\", \"hdemucs_mmi\", segment_path, \"--out\", \"/content\", \"--mp3-preset\", \"7\"])\n",
        "\n",
        "    # Unir todos los resultados en un solo archivo de audio\n",
        "    # Definir la ruta de la carpeta que contiene los segmentos de audio\n",
        "    folder_path = '/content/hdemucs_mmi'\n",
        "\n",
        "    # Obtener una lista de todas las carpetas en la carpeta de segmentos\n",
        "    folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
        "\n",
        "    # Ordenar la lista de carpetas para asegurarse de que los segmentos se unan en el orden correcto\n",
        "    # Aqu√≠ asumimos que el nombre de la carpeta termina con el n√∫mero de segmento\n",
        "    folders.sort(key=lambda x: int(x.rsplit('segment', 1)[-1]))\n",
        "\n",
        "    # Crear un objeto AudioSegment vac√≠o para almacenar el audio combinado\n",
        "    combined = AudioSegment.empty()\n",
        "\n",
        "    # Para cada carpeta, buscar el archivo \"vocals.mp3\"\n",
        "    for folder in folders:\n",
        "        vocals_file = os.path.join(folder_path, folder, 'vocals.mp3')\n",
        "        if os.path.isfile(vocals_file):\n",
        "            # Cargar el audio y agregarlo a un objeto AudioSegment combinado\n",
        "            audio_segment = AudioSegment.from_mp3(vocals_file)\n",
        "            combined += audio_segment\n",
        "\n",
        "    # Exportar el objeto AudioSegment combinado a un archivo de audio mp3\n",
        "    combined.export('/content/result/vocals.mp3', format='mp3')\n",
        "\n",
        "    # Borrar la carpeta hdemucs_mmi y todo su contenido\n",
        "    shutil.rmtree('/content/hdemucs_mmi')\n",
        "else:\n",
        "    # Si la duraci√≥n es menor o igual a la duraci√≥n m√°xima, aplicar demucs directamente al audio\n",
        "    demucs.separate.main([\"-d\", \"cuda\", \"--mp3\", \"--mp3-bitrate\", \"96\", \"--two-stems=vocals\", \"-n\", \"hdemucs_mmi\", audio_path, \"--out\", \"/content\", \"--mp3-preset\", \"7\"])\n",
        "\n",
        "    # Mover el archivo de audio resultante a la carpeta de resultados\n",
        "    output_path = '/content/hdemucs_mmi/audio_16_000/vocals.mp3'\n",
        "    if os.path.isfile(output_path):\n",
        "        shutil.move(output_path, '/content/result/vocals.mp3')\n",
        "        # Borrar la carpeta hdemucs_mmi y todo su contenido\n",
        "        shutil.rmtree('/content/hdemucs_mmi')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tUbF1ATPSLh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **2. Transcripci√≥n De Voz ‚úçÔ∏è**\n",
        "#@markdown Ahora, vamos a transcribir tu archivo de audio.\n",
        "import whisperx\n",
        "import gc\n",
        "\n",
        "audio_file = \"/content/result/vocals.mp3\" #@param ['/content/result/vocals.mp3', '/content/audio_16_000.mp3']\n",
        "from_language= 'es' #@param ['af', 'am', 'ar', 'as', 'az', 'ba', 'be', 'bg', 'bn', 'bo', 'br', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'gl', 'gu', 'ha', 'haw', 'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jw', 'ka', 'kk', 'km', 'kn', 'ko', 'la', 'lb', 'ln', 'lo', 'lt', 'lv', 'mg', 'mi', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'my', 'ne', 'nl', 'nn', 'no', 'oc', 'pa', 'pl', 'ps', 'pt', 'ro', 'ru', 'sa', 'sd', 'si', 'sk', 'sl', 'sn', 'so', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'tg', 'th', 'tk', 'tl', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'yi', 'yo', 'zh']{allow-input: true}\n",
        "device = \"cuda\"\n",
        "chunk_size = 10\n",
        "batch_size = 16\n",
        "compute_type = \"float16\"\n",
        "beam_size = 10\n",
        "no_align = True\n",
        "print_progress = True\n",
        "\n",
        "model = whisperx.load_model(\"large-v3\", device, compute_type=compute_type)\n",
        "audio = whisperx.load_audio(audio_file)\n",
        "\n",
        "# Transcription\n",
        "result = model.transcribe(\n",
        "    audio,\n",
        "    batch_size=batch_size,\n",
        "    chunk_size=chunk_size,\n",
        "    language=from_language,\n",
        "    print_progress=print_progress\n",
        ")\n",
        "print(result[\"segments\"])\n",
        "\n",
        "#srt\n",
        "from whisperx.utils import WriteSRT\n",
        "\n",
        "audio_filename = audio_file.split(\"/\")[-1]\n",
        "srt_filename = audio_filename.split(\".\")[0] + \".srt\"\n",
        "\n",
        "with open(srt_filename, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writesrt=WriteSRT(\".\")  #output file directory\n",
        "    writesrt.write_result(result=result, file=srt,options={\"max_line_width\":None,\"max_line_count\":None,\"highlight_words\":False,\"chunk_size\":10})\n",
        "\n",
        "#vtt\n",
        "from whisperx.utils import WriteSRT\n",
        "\n",
        "audio_filename = audio_file.split(\"/\")[-1]\n",
        "srt_filename = audio_filename.split(\".\")[0] + \".vtt\"\n",
        "\n",
        "with open(srt_filename, \"w\", encoding=\"utf-8\") as srt:\n",
        "    writesrt=WriteSRT(\".\")  #output file directory\n",
        "    writesrt.write_result(result=result, file=srt,options={\"max_line_width\":None,\"max_line_count\":None,\"highlight_words\":False,\"chunk_size\":10})\n",
        "\n",
        "#@markdown - Si deseas que WhisperX detecte autom√°ticamente el idioma, simplemente debes dejar vac√≠o el campo \"from_language\", es decir, no debe contener ning√∫n car√°cter, para la detecci√≥n autom√°tica.\n",
        "\n",
        "#@markdown Para usar unicamente las vocales: _**/content/result/vocals.mp3**_\n",
        "\n",
        "#@markdown Para usar el audio original: _**/content/audio_16_000.mp3**_\n",
        "\n",
        "### Download vocals.vtt üìÇ\n",
        "Download_vocals_vtt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_vtt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals.vtt\")\n",
        "### Download vocals.srt üìÇ\n",
        "Download_vocals_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals.srt\")\n",
        "\n",
        "### Download audio_16_000.vtt üìÇ\n",
        "Download_audio_16_000_vtt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_vtt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000.vtt\")\n",
        "### Download audio_16_000.srt üìÇ\n",
        "Download_audio_16_000_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000.srt\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nEtnuVGSpkfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **3. Traduzca Su Subtitulo! üåç**\n",
        "#@markdown Traduce tu subt√≠tulo y trad√∫celo a otro idioma. Puedes usar m√°s de 6 traductores para elegir.\n",
        "import ip_rotator\n",
        "proxy = ip_rotator.Proxy(https = True)\n",
        "import translators\n",
        "import srt\n",
        "\n",
        "def get_user_input():\n",
        "  \"\"\"Prompts the user to choose the SRT file and returns the filename.\"\"\"\n",
        "  while True:\n",
        "    filename = input(\"Enter the SRT filename (audio_16_000.srt or vocals.srt): \")\n",
        "    if filename in (\"audio_16_000.srt\", \"vocals.srt\"):\n",
        "      return filename\n",
        "    else:\n",
        "      print(\"Invalid filename. Please choose 'audio_16_000.srt' or 'vocals.srt'.\")\n",
        "\n",
        "# Read the original SRT file based on user input\n",
        "filename = get_user_input()\n",
        "base_filename, _ = os.path.splitext(filename)  # Extract base filename without extension\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "  subtitles = srt.parse(f.read())\n",
        "\n",
        "# Function to translate a subtitle (consider error handling)\n",
        "def translate_subtitle(subtitle):\n",
        "  try:\n",
        "    translated_content = translators.translate_text(\n",
        "        query_text=subtitle.content,\n",
        "        from_language=\"auto\"#@param {type:\"string\"}\n",
        "        ,\n",
        "        to_language=\"en\"#@param {type:\"string\"}\n",
        "        ,\n",
        "        translator=\"google\" #@param ['alibaba', 'apertium', 'argos', 'baidu', 'bing', 'caiyun', 'cloudTranslation', 'elia', 'google', 'hujiang', 'iciba', 'iflytek', 'iflyrec', 'itranslate', 'judic', 'languageWire', 'lingvanex', 'niutrans', 'mglip', 'mirai', 'modernMt', 'myMemory', 'papago', 'qqFanyi', 'qqTranSmart', 'reverso', 'sogou', 'sysTran', 'tilde', 'translateCom', 'translateMe', 'utibet', 'volcEngine', 'yandex', 'yeekit', 'youdao']{allow-input: true}\n",
        "    )\n",
        "    print(f\" Subtitle Results {subtitle.index}:\")\n",
        "    print(f\"  Original: {subtitle.content}\")\n",
        "    print(f\"  Translation: {translated_content}\")\n",
        "    return srt.Subtitle(subtitle.index, subtitle.start, subtitle.end, translated_content)\n",
        "  except Exception as e:  # Catch potential translation errors\n",
        "    print(f\"Error translating subtitle {subtitle.index}: {e}\")\n",
        "    return subtitle  # Return the original subtitle if translation fails\n",
        "\n",
        "# Translate each subtitle\n",
        "translated_subtitles = [translate_subtitle(subtitle) for subtitle in subtitles]\n",
        "\n",
        "# Write the translated subtitles to a new file with modified name\n",
        "translated_filename = f\"{base_filename}_translated_by_translators.srt\"\n",
        "with open(translated_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write(srt.compose(translated_subtitles))\n",
        "\n",
        "### Download the translated SRT file (optional)\n",
        "Download_srt = False  # Set to True to download the file\n",
        "\n",
        "if Download_srt:\n",
        "  from google.colab import files  # Assuming you're using Google Colab\n",
        "  files.download(translated_filename)\n",
        "\n",
        "### Download result srt üìÇ\n",
        "Download_audio_16_000_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_16_000_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000_translated_by_translators.srt\")\n",
        "\n",
        "### Download result srt üìÇ\n",
        "Download_vocals_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocals_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals_translated_by_translators.srt\")\n",
        "\n",
        "#@markdown Subtitulo De Vocales: _**/content/vocals.srt**_\n",
        "\n",
        "#@markdown Subtitulo Del Audio Original: _**/content/audio_16_000.srt**_"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nVoPlS2N4CiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # <font color=somblue>**DeepL Unlimited Subtitles!** <font color=d5d5d5> *Best Translator.*\n",
        "#@markdown ¬°Traduce tus subt√≠tulos con gran precisi√≥n usando DeepL de forma ilimitadamente!\n",
        "Source_Language = \"auto\" # @param ['ar', 'auto', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'uk', 'zh']{allow-input: true}\n",
        "\n",
        "#@title Target Language\n",
        "Target_Language = \"en\" #@param ['ar', 'bg', 'cs', 'da', 'de', 'el', 'en', 'es', 'et', 'fi', 'fr', 'hu', 'id', 'it', 'ja', 'ko', 'lt', 'lv', 'nb', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sv', 'tr', 'uk', 'zh']{allow-input: true}\n",
        "\n",
        "import os\n",
        "\n",
        "# SRT File\n",
        "from srtranslator import SrtFile\n",
        "\n",
        "from srtranslator.translators.pydeeplx import PyDeepLX\n",
        "translator = PyDeepLX()\n",
        "filepath = \"/content/vocals.srt\" #@param ['/content/audio_16_000.srt','/content/vocals.srt']\n",
        "\n",
        "# SRT File\n",
        "sub = SrtFile(filepath)\n",
        "# Translate\n",
        "sub.translate(translator, Source_Language, Target_Language)\n",
        "\n",
        "# Making the result subtitles prettier\n",
        "sub.wrap_lines()\n",
        "sub.save(f\"{os.path.splitext(filepath)[0]}_translated_by_DeepL.srt\")\n",
        "\n",
        "### Download result üìÇ\n",
        "Download_vocal_srt = False # @param{type:\"boolean\"}\n",
        "if Download_vocal_srt:\n",
        " from google.colab import files\n",
        " files.download (\"vocals_translated_by_DeepL.srt\")\n",
        "\n",
        "### Download result üìÇ\n",
        "Download_audio_srt = False # @param{type:\"boolean\"}\n",
        "if Download_audio_srt:\n",
        " from google.colab import files\n",
        " files.download (\"audio_16_000_translated_by_DeepL.srt\")\n",
        "\n",
        "#@markdown Para subt√≠tulos con vocales: _**/content/vocals.srt**_\n",
        "\n",
        "#@markdown Para subt√≠tulos del audio original: _**/content/audio_16_000.srt**_\n",
        "\n",
        "#@markdown **Advertencia:**\n",
        "#@markdown *El uso de este traductor garantizar√° traducciones muy buenas, pero no es r√°pido. La duraci√≥n del proceso de traducci√≥n depende de la longitud de sus subt√≠tulos para traducir.*\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FMxqdZVVnARL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lenguajes disponibles para DeepL.** üó®Ô∏è\n"
      ],
      "metadata": {
        "id": "IIILsnqTUn6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "'ar': Arabic\n",
        "'auto': Auto\n",
        "'bg': Bulgaria\n",
        "'cs': Czech\n",
        "'da': Danish\n",
        "'de': German\n",
        "'el': Greek\n",
        "'en': English\n",
        "'es': Spanish\n",
        "'et': Estonian\n",
        "'fi': Finnish\n",
        "'fr': French\n",
        "'hu': Hungarian\n",
        "'id': Indonesian\n",
        "'it': Italian\n",
        "'ja': Japanese\n",
        "'ko': Korean\n",
        "'lt': Lithuanian\n",
        "'lv': Latvian\n",
        "'nb': Norwegian Bokm√•l\n",
        "'nl': Dutch\n",
        "'pl': Polish\n",
        "'pt': Portuguese\n",
        "'ro': Romanian\n",
        "'ru': Russian\n",
        "'sk': Slovak\n",
        "'sl': Slovenian\n",
        "'sv': Swedish\n",
        "'tr': Turkish\n",
        "'uk': Ukrainian\n",
        "'zh': Chinese\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "BEd1NVOvZmTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cr√©ditos y Agradecimientos Especiales**\n",
        "Este notebook, combina muchas librerias gratuitas provenientes de Github y PyPI para lograr hacer su cometido. A continuacion, compartire cuales son:\n",
        "\n",
        "- [**WhisperX** - Inteligencia Artificial Para transcribir](https://github.com/m-bain/whisperX)\n",
        "- [**Translators** - Librebria con Api para mas de 10 idiomas](https://pypi.org/project/translators/)\n",
        "- [**Srt** - Necesario para leer Archivos .srt](https://pypi.org/project/srt/)\n",
        "- [**Demucs** - Para la extracion de voz](https://pypi.org/project/demucs/)\n",
        "- [**Ctranslate2** - Necesario para WhisperX](https://pypi.org/project/ctranslate2/)\n",
        "- [**Yt-dlp** - para la descarga de videos](https://pypi.org/project/yt-dlp/)\n",
        "- [**Ip-Rotator** - Proxy para Apis](https://pypi.org/project/ip-rotator/)\n",
        "- [**Srtranslator** - Traduccion De Subtitulos Con Deepl](https://pypi.org/project/srtranslator/)\n",
        "\n",
        "Aclaracion Importante, este notebook tambien utiliza codigo propio para la creacion de subtitulos; Translators **No fue creado para traducir subtitulos, tuve que escribir yo el codigo para que funcionara de esa forma.** Aun asi, ¬°Agradezco enormemente el equipo detr√°s de todos estos proyectos, son importantes para hacer posible este proyecto! Sin nada mas que decir, Disfruta de este proyecto!"
      ],
      "metadata": {
        "id": "TwtSHHeDRbb3"
      }
    }
  ]
}